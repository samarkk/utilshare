# go to the master
hvcek
zookeeper-server-start -daemon zookeeper.properties
tlpg 2181
jps
kafka-server-start -daemon server.properties.orig
tlpg 9092
kafka-topics --bootstrap-server master:9092 --create --topic first-topic --partitions 3 --replication-factor 1
# in one pane
kafka-console-producer --bootstrap-server master:9092 --topic first-topic
# in the other pane
kafka-console-consumer --bootstrap-server master:9092 --topic first-topic --from-beginning
grep log.dirs /home/vagrant/confluent/etc/kafka/server.properties.orig
ls -l /tmp/kafka-logs
# stop the consumer and run the command on line number 12 withou --from-beginning
# no data will appear
# then run the following
kafka-console-consumer --bootstrap-server master:9092 --topic first-topic --from-beginning --property print.key=true --property print.offset=true --property print.partition=true --property print.timestamp=true
kafka-console-producer --bootstrap-server master:9092 --topic first-topic --property parse.key=true --property key.separator=, --property ignore.error=true
kafka-console-consumer --bootstrap-server master:9092 --topic first-topic --from-beginning --property print.key=true --group first-group
kafka-consumer-groups  --bootstrap-server master:9092 --list
kafka-consumer-groups  --bootstrap-server master:9092 --describe --group first-group
kafka-console-consumer --bootstrap-server master:9092 --topic first-topic --from-beginning --property print.key=true --group second-group
https://github.com/samarkk/spark-python/blob/main/streaming/structured_kafka_word_count.py
pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1
cd /home/vagrant/c/data/201819/cm
for x in ./*;do gunzip $x;done
